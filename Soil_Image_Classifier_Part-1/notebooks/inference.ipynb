{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a9092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Team Name: Creatix\n",
    "Team Members: Siddharth Malkania, Krishan Verma , Rishi Mehrotra\n",
    "Leaderboard Rank: 117\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the notebook used for making the inferences using the model trained.\n",
    "# Inference Notebook for Soil Classification\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# GPU optimization (optional)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(f\"GPU acceleration enabled: {len(physical_devices)} GPU(s) found\")\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Paths (update as needed)\n",
    "MODEL_PATH = '/kaggle/input/your-model-directory/model.h5'\n",
    "TEST_DIR = '/kaggle/input/soilcl/soil_classification-2025/test'\n",
    "TEST_CSV = '/kaggle/input/soilcl/soil_classification-2025/test_ids.csv'\n",
    "\n",
    "# Prepare test data\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# If images need to be converted to JPG, use the convert_to_jpg function from your training notebook\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=TEST_DIR,\n",
    "    x_col='image_id',\n",
    "    y_col=None,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Rebuild model architecture (must match training)\n",
    "def build_model():\n",
    "    base_model = DenseNet121(weights=None, include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# Load trained weights\n",
    "model = build_model()\n",
    "model.load_weights(MODEL_PATH)\n",
    "print(\"Loaded trained model weights.\")\n",
    "\n",
    "# Predict on test data\n",
    "test_generator.reset()\n",
    "preds = model.predict(test_generator, steps=int(np.ceil(test_generator.samples/BATCH_SIZE)))\n",
    "predicted_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Map integer labels to class names (update mapping as per your training)\n",
    "class_indices = {'Clay soil': 0, 'Red Soil': 1, 'Sandy Soil': 2, 'Black Soil': 3}\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "predicted_labels = [idx_to_class[idx] for idx in predicted_classes]\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    'image_id': test_df['image_id'],\n",
    "    'soil_type': predicted_labels\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Inference complete. Submission file saved as submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
